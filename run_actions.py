#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
NewsTrace GitHub Actions è¿è¡Œå…¥å£
é›¶æˆæœ¬éƒ¨ç½²ä¸“ç”¨è„šæœ¬
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def setup_environment():
    """é…ç½®è¿è¡Œç¯å¢ƒ"""
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    Path("data").mkdir(exist_ok=True)
    Path("data/reports").mkdir(exist_ok=True)
    
    # è®¾ç½®æ•°æ®åº“è·¯å¾„ (SQLite)
    os.environ.setdefault("DATABASE_URL", "sqlite:///data/newstrace.db")
    
    # æ£€æµ‹ LLM é…ç½®
    if os.getenv("GEMINI_API_KEY"):
        os.environ.setdefault("LLM_PROVIDER", "gemini")
        logger.info("âœ… ä½¿ç”¨ Gemini (å…è´¹) ä½œä¸º LLM æä¾›å•†")
    elif os.getenv("OPENAI_API_KEY"):
        os.environ.setdefault("LLM_PROVIDER", "openai")
        logger.info("âœ… ä½¿ç”¨ OpenAI ä½œä¸º LLM æä¾›å•†")
    else:
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ° LLM API Key")
    
    logger.info(f"âœ… ç¯å¢ƒé…ç½®å®Œæˆ, æ•°æ®ç›®å½•: {Path('data').absolute()}")


def get_watch_keywords():
    """è·å–å…³æ³¨å…³é”®è¯"""
    keywords_str = os.getenv("WATCH_KEYWORDS", "é»„é‡‘,èŒ…å°,è‹±ä¼Ÿè¾¾,å¤®è¡Œ,GDP")
    return [k.strip() for k in keywords_str.split(",") if k.strip()]


def run_audit_mode():
    """è¿è¡Œå®¡è®¡æ¨¡å¼"""
    logger.info("ğŸ“° å¼€å§‹æ–°é—»é‡‡é›†ä¸å®¡è®¡...")
    
    from src.news_fetcher import NewsFetcher
    from src.audit_engine import AuditEngine
    from src.multi_channel_notifier import MultiChannelNotifier
    
    # åˆå§‹åŒ–ç»„ä»¶
    fetcher = NewsFetcher({"provider": "akshare"})
    
    # æ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹© LLM
    provider = os.getenv("LLM_PROVIDER", "gemini")
    audit_config = {
        "provider": provider,
        "model": os.getenv("LLM_MODEL", "gemini-2.0-flash" if provider == "gemini" else "gpt-4o"),
        "api_key": os.getenv("GEMINI_API_KEY") or os.getenv("OPENAI_API_KEY")
    }
    
    if provider == "openai" and os.getenv("OPENAI_BASE_URL"):
        audit_config["base_url"] = os.getenv("OPENAI_BASE_URL")
    
    auditor = AuditEngine(audit_config)
    notifier = MultiChannelNotifier()
    
    # è·å–å…³æ³¨å…³é”®è¯
    keywords = get_watch_keywords()
    logger.info(f"ğŸ“‹ å…³æ³¨å…³é”®è¯: {keywords}")
    
    # é‡‡é›†æ–°é—» (NewsFetcher.fetch() ä¸æ¥å— limit å‚æ•°)
    news_list = fetcher.fetch()
    logger.info(f"ğŸ“° é‡‡é›†åˆ° {len(news_list)} æ¡æ–°é—»")
    
    # å®¡è®¡æ–°é—»
    results = []
    high_risk_news = []
    
    for news in news_list:
        try:
            result = auditor.audit(news)
            results.append(result)
            
            # ä¿®å¤: æ­£ç¡®è®¿é—®å®¡è®¡ç»“æœç»“æ„
            audit_result = result.get("audit_result", {})
            risk_level = audit_result.get("risk_level", "Medium")
            
            if risk_level in ["High", "high", "critical", "Critical"]:
                high_risk_news.append({
                    "title": news.get("title"),
                    "risk_level": risk_level,
                    "score": audit_result.get("score", 50),
                    "core_thesis": audit_result.get("core_thesis") or audit_result.get("one_sentence_conclusion", "N/A")
                })
        except Exception as e:
            logger.error(f"å®¡è®¡å¤±è´¥: {e}")
    
    logger.info(f"âœ… å®¡è®¡å®Œæˆ, é«˜é£é™©æ–°é—»: {len(high_risk_news)} æ¡")
    
    # ä¿®å¤: å§‹ç»ˆç”ŸæˆæŠ¥å‘Š,ä¸ç®¡æ˜¯å¦æœ‰é«˜é£é™©æ–°é—»
    report = generate_daily_report(results, high_risk_news)
    
    # æ¨é€é€šçŸ¥ (åªåœ¨æœ‰é«˜é£é™©æ–°é—»æ—¶æ¨é€)
    if high_risk_news and notifier.is_available():
        notifier.send(f"ğŸ“Š NewsTrace æ—¥æŠ¥ {datetime.now().strftime('%Y-%m-%d')}", report)
        logger.info(f"ğŸ“¤ å·²æ¨é€é€šçŸ¥: {len(high_risk_news)} æ¡é«˜é£é™©æ–°é—»")
    
    # ä¿å­˜æŠ¥å‘Š (å§‹ç»ˆä¿å­˜)
    report_path = f"data/reports/daily_{datetime.now().strftime('%Y%m%d')}.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    logger.info(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    return results


def run_tracking_mode():
    """è¿è¡Œè¿½è¸ªæ¨¡å¼"""
    logger.info("ğŸ“ˆ å¼€å§‹è¿½è¸ªæ›´æ–°...")
    
    # TODO: å®ç°è¿½è¸ªé€»è¾‘
    logger.info("âœ… è¿½è¸ªæ›´æ–°å®Œæˆ")


def generate_daily_report(results, high_risk_news):
    """ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š"""
    report_lines = [
        f"# ğŸ“Š NewsTrace æ¯æ—¥åˆ†ææŠ¥å‘Š",
        f"",
        f"**æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"",
        f"---",
        f"",
        f"## ğŸ“° åˆ†ææ¦‚è§ˆ",
        f"",
        f"- å®¡è®¡æ–°é—»: {len(results)} æ¡",
        f"- é«˜é£é™©æ–°é—»: {len(high_risk_news)} æ¡",
        f"",
    ]
    
    if high_risk_news:
        report_lines.extend([
            f"## âš ï¸ é«˜é£é™©æ–°é—»",
            f""
        ])
        
        for i, news in enumerate(high_risk_news[:5], 1):
            emoji = "ğŸ”´" if news["risk_level"] in ["critical", "Critical"] else "ğŸŸ "
            report_lines.extend([
                f"### {emoji} {i}. {news['title'][:50]}...",
                f"",
                f"- **é£é™©ç­‰çº§**: {news['risk_level']}",
                f"- **è¯„åˆ†**: {news['score']}",
                f"- **æ ¸å¿ƒè®ºç‚¹**: {news.get('core_thesis', 'N/A')}",
                f""
            ])
    else:
        report_lines.extend([
            f"## âœ… æ— é«˜é£é™©æ–°é—»",
            f"",
            f"æœ¬æ¬¡åˆ†ææœªå‘ç°é«˜é£é™©æ–°é—»,æ‰€æœ‰æ–°é—»é£é™©ç­‰çº§å‡ä¸º Medium æˆ– Lowã€‚",
            f""
        ])
    
    # æ·»åŠ æ‰€æœ‰æ–°é—»çš„æ‘˜è¦
    report_lines.extend([
        f"## ğŸ“‹ æ‰€æœ‰åˆ†ææ–°é—»æ‘˜è¦",
        f""
    ])
    
    for i, result in enumerate(results[:10], 1):
        audit_result = result.get("audit_result", {})
        risk_level = audit_result.get("risk_level", "Medium")
        score = audit_result.get("score", 50)
        
        # é£é™©ç­‰çº§å›¾æ ‡
        if risk_level in ["High", "high", "Critical", "critical"]:
            emoji = "ğŸ”´"
        elif risk_level in ["Medium", "medium"]:
            emoji = "ğŸŸ¡"
        else:
            emoji = "ğŸŸ¢"
        
        report_lines.append(f"{i}. {emoji} é£é™©: {risk_level} | è¯„åˆ†: {score}")
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"*ç”± NewsTrace è‡ªåŠ¨ç”Ÿæˆ*"
    ])
    
    return "\n".join(report_lines)


def save_summary(results):
    """ä¿å­˜è¿è¡Œæ‘˜è¦"""
    summary = {
        "run_time": datetime.now().isoformat(),
        "total_analyzed": len(results),
        "high_risk_count": sum(1 for r in results if r.get("risk_level") in ["high", "critical"]),
        "provider": os.getenv("LLM_PROVIDER", "unknown")
    }
    
    with open("data/summary.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)


def main():
    """ä¸»å…¥å£"""
    print("\n" + "=" * 50)
    print("ğŸ“Š NewsTrace é›¶æˆæœ¬éƒ¨ç½²ç‰ˆ")
    print("=" * 50 + "\n")
    
    # é…ç½®ç¯å¢ƒ
    setup_environment()
    
    # è·å–è¿è¡Œæ¨¡å¼
    mode = os.getenv("RUN_MODE", "full")
    logger.info(f"ğŸš€ è¿è¡Œæ¨¡å¼: {mode}")
    
    results = []
    
    try:
        if mode in ("full", "audit"):
            results = run_audit_mode()
        
        if mode in ("full", "tracking"):
            run_tracking_mode()
        
        # ä¿å­˜æ‘˜è¦
        save_summary(results)
        
        logger.info("âœ… NewsTrace è¿è¡Œå®Œæˆ!")
        
    except Exception as e:
        logger.error(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
