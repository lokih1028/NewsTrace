import os
import time
import json
import requests
import datetime
from sqlalchemy import create_engine, text
from openai import OpenAI
from src.news_fetcher import NewsFetcher
from src.rate_limiter import AdaptiveRateLimiter
from src.audit_engine import AuditEngine
from src.cost_tracker import CostTracker

# ==================== Sentry å¼‚å¸¸ç›‘æ§ ====================
try:
    import sentry_sdk
    SENTRY_DSN = os.getenv("SENTRY_DSN")
    if SENTRY_DSN:
        sentry_sdk.init(
            dsn=SENTRY_DSN,
            traces_sample_rate=0.1,
            environment=os.getenv("ENV", "development")
        )
        print("âœ… Sentry å¼‚å¸¸ç›‘æ§å·²å¯ç”¨")
    else:
        print("âš ï¸ SENTRY_DSN æœªé…ç½®,å¼‚å¸¸ç›‘æ§ç¦ç”¨")
except ImportError:
    print("âš ï¸ sentry-sdk æœªå®‰è£…,å¼‚å¸¸ç›‘æ§ç¦ç”¨")
# =========================================================

# ==================== æ ¸å¿ƒé…ç½®åŒº ====================
# 1. ä½ çš„ OpenAI Key (å¿…é¡»å¼€å¯ VPN)
API_KEY = os.getenv("OPENAI_API_KEY", "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")
BASE_URL = "https://api.openai.com/v1"
MODEL_NAME = "gpt-4o"

# 2. ä½ çš„ PushPlus Token (å¾®ä¿¡æ¨é€ç”¨)
PUSH_TOKEN = os.getenv("PUSHPLUS_TOKEN", "a348f2f0e5b545f79a96acb472c20fb6")

# 3. ä½ çš„å…³æ³¨æ¸…å• (Active Input)
WATCH_KEYWORDS = ["é»„é‡‘", "èŒ…å°", "è‹±ä¼Ÿè¾¾", "å¤®è¡Œ", "GDP"] 

# 4. é‡‡é›†é¢‘ç‡ (ç§’)
Loop_Interval = 20 

# æ•°æ®åº“è¿æ¥
DB_URI = os.getenv("DATABASE_URL", "postgresql://postgres:123456@localhost:5432/newstrace")
# ====================================================

print("\n=== NewsTrace 3.0 (7x24h å®æ—¶é›·è¾¾ç‰ˆ) å¯åŠ¨ ===")


from src.multi_channel_notifier import MultiChannelNotifier

try:
    db_engine = create_engine(DB_URI)
    ai_client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    # åˆå§‹åŒ–æ–°ç»„ä»¶
    fetcher = NewsFetcher({"provider": "tushare", "api_key": "your_tushare_token"}) 
    rate_limiter = AdaptiveRateLimiter(min_interval=Loop_Interval, max_interval=Loop_Interval*2)
    audit_engine = AuditEngine({"provider": "openai", "model": MODEL_NAME, "api_key": API_KEY})
    
    # åˆå§‹åŒ–æ¨é€ç®¡ç†å™¨ (ä½¿ç”¨æ–°ç‰ˆå¤šæ¸ é“é€šçŸ¥å™¨)
    notifier = MultiChannelNotifier({
        "pushplus_token": PUSH_TOKEN,
        # "wechat_webhook": "...", # å¯é€‰
        # "feishu_webhook": "...", # å¯é€‰
    })
    
    # éªŒè¯æ•°æ®åº“è¿æ¥
    try:
        with db_engine.connect() as conn: conn.execute(text("SELECT 1"))
        print("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
    except Exception as db_e:
        print(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ (ç¨‹åºå°†ç»§ç»­è¿è¡Œ,ä½†æ— æ³•ä¿å­˜æ•°æ®): {db_e}")

    print("âœ… åŸºç¡€è®¾æ–½åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}"); exit()

# --- å†…å­˜ç¼“å­˜ (ç”¨äºå»é‡) ---
seen_news_ids = set()

def process_news_item(item):
    """å¤„ç†å•æ¡æ–°é—»"""
    news_id = item.get('docid') or f"NEWS_{hash(item['title'])}"
    title = item['title']
    
    if news_id in seen_news_ids:
        return
    
    # æ•°æ®åº“å»é‡
    try:
        with db_engine.connect() as conn:
            exists = conn.execute(text("SELECT 1 FROM news_intelligence WHERE news_id = :id"), {"id": news_id}).fetchone()
            if exists:
                seen_news_ids.add(news_id)
                return
    except:
        pass

    # é»‘åå•è¿‡æ»¤ - åªè¿‡æ»¤æ˜æ˜¾æ— å…³çš„æ–°é—»
    BLACKLIST_KEYWORDS = ["å¨±ä¹", "ä½“è‚²", "æ¸¸æˆ", "æ˜æ˜Ÿ", "å½±è§†", "ç»¼è‰º", "ç”µç«", "èµ›äº‹", "çƒå‘˜", "æ¼”å‘˜"]
    if any(kw in title for kw in BLACKLIST_KEYWORDS):
        logger.debug(f"â›” é»‘åå•è¿‡æ»¤: {title}")
        seen_news_ids.add(news_id)
        return

    # æ‰€æœ‰å…¶ä»–æ–°é—»éƒ½è¿›å…¥å®¡è®¡æµç¨‹
    print(f"\nâš¡ å‘ç°æ–°æƒ…æŠ¥: {title}")
    
    try:
        # ä½¿ç”¨ AuditEngine è¿›è¡Œå®¡è®¡
        audit_output = audit_engine.audit(item)
        res_json = audit_output.get('audit_result', {})
        
        # å­˜å…¥æ•°æ®åº“
        try:
            with db_engine.connect() as conn:
                conn.execute(text("""
                    INSERT INTO news_intelligence (news_id, raw_content, publish_time, ai_audit_result)
                    VALUES (:id, :c, :t, :j)
                """), {"id": news_id, "c": title, "t": datetime.datetime.now(), "j": json.dumps(audit_output)})
        except Exception as db_e:
            print(f"âš ï¸ æ•°æ®åº“å†™å…¥å¤±è´¥: {db_e}")
            
        seen_news_ids.add(news_id)
        
        # ç»Ÿä¸€æ¨é€
        notifier.broadcast(title, title, res_json)

    except Exception as e:
        print(f"âš ï¸ å¤„ç†å‡ºé”™: {e}")

import argparse

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='NewsTrace 3.0')
    parser.add_argument('--mode', type=str, default='loop', choices=['loop', 'single_run'],
                        help='è¿è¡Œæ¨¡å¼: loop (æŒç»­ç›‘æ§) æˆ– single_run (å•æ¬¡è¿è¡Œ)')
    parser.add_argument('--dry-run', action='store_true', help='ä»…è·å–æ•°æ®,ä¸è¿›è¡Œ AI åˆ†æ')
    return parser.parse_args()

# ================= ä¸»å¾ªç¯ =================
if __name__ == "__main__":
    args = parse_arguments()
    
    # åˆå§‹åŒ–æƒé‡è¿›åŒ–å™¨
    try:
        from src.weight_evolver import WeightEvolver
        import yaml
        with open('config/config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        weight_evolver = WeightEvolver(db_engine, config)
        print("âœ… æƒé‡è¿›åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ æƒé‡è¿›åŒ–å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
        weight_evolver = None
    
    print(f"ğŸ‘€ æ­£åœ¨ç›‘æ§å…³é”®è¯: {WATCH_KEYWORDS if WATCH_KEYWORDS else 'ALL (å…¨éƒ¨æ¨é€)'}")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print("----------------------------------------")
    
    evolution_check_counter = 0  # è¿›åŒ–æ£€æŸ¥è®¡æ•°å™¨
    
    while True:
        try:
            # 1. å¤šæºå®¹é”™è·å–æœ€æ–°åˆ—è¡¨
            news_list = fetcher.fetch_with_fallback()
            
            if news_list:
                rate_limiter.record_result(True)
                for item in reversed(news_list):
                    process_news_item(item)
            else:
                rate_limiter.record_result(False)
            
            # 2. æƒé‡è¿›åŒ–æ£€æŸ¥ï¼ˆæ¯10æ¬¡å¾ªç¯æ£€æŸ¥ä¸€æ¬¡ï¼‰
            evolution_check_counter += 1
            if weight_evolver and evolution_check_counter >= 10:
                evolution_check_counter = 0
                should_evolve, reason = weight_evolver.should_evolve()
                if should_evolve:
                    print(f"\nğŸ§¬ è§¦å‘æƒé‡è¿›åŒ–: {reason}")
                    new_weights = weight_evolver.evolve()
                    # æ›´æ–°å®¡è®¡å¼•æ“çš„åŠ¨æ€æƒé‡
                    if hasattr(audit_engine, 'dynamic_weights'):
                        audit_engine.dynamic_weights = new_weights
                    print("âœ… æƒé‡è¿›åŒ–å®Œæˆ")
            
            # 3. æ¨¡å¼åˆ¤æ–­
            if args.mode == 'single_run':
                print("\nâœ… å•æ¬¡è¿è¡Œæ¨¡å¼å®Œæˆ, é€€å‡ºç¨‹åºã€‚")
                break
                
            # 4. è‡ªé€‚åº”ä¼‘æ¯
            print(".", end="", flush=True)
            rate_limiter.wait()
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·åœæ­¢ç›‘æ§")
            break
        except Exception as e:
            print(f"\nâŒ è¿è¡Œå¼‚å¸¸: {e}")
            if args.mode == 'single_run':
                break
            rate_limiter.record_result(False)
            rate_limiter.wait()
