"""
AIå®¡è®¡å¼•æ“
ä½¿ç”¨LLMè¿›è¡Œæ–°é—»è¯­ä¹‰å®¡è®¡
"""
import logging
import json
import random
import datetime
from typing import Dict
import os

from .llm_cache import LLMCache

logger = logging.getLogger(__name__)


class AuditEngine:
    """AIå®¡è®¡å¼•æ“"""
    
    def __init__(self, config: Dict, db=None):
        """
        åˆå§‹åŒ–å®¡è®¡å¼•æ“
        
        Args:
            config: LLMé…ç½®
            db: æ•°æ®åº“å®ä¾‹(å¯é€‰,ç”¨äºåŠ è½½åŠ¨æ€æƒé‡)
        """
        self.config = config
        self.provider = config.get('provider', 'openai')
        self.model = config.get('model', 'gpt-4o')
        self.api_key = config.get('api_key') or os.getenv('OPENAI_API_KEY')
        # æ–¹æ¡ˆ2: æé«˜åŸºç¡€ temperature å¹¶å¼•å…¥éšæœºæ³¢åŠ¨å¢åŠ è¾“å‡ºå¤šæ ·æ€§\r\n        base_temp = config.get('temperature', 0.5)\r\n        self.temperature = base_temp + random.uniform(-0.1, 0.1)
        self.max_tokens = config.get('max_tokens', 2000)
        self.thinking_level = config.get('thinking_level', 'low')  # æ–°å¢: Gemini 3 æ€è€ƒç­‰çº§
        self.db = db
        
        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.prompt_template = self._load_prompt_template()
        
        # åŠ è½½JSON Schema
        self.json_schema = self._load_json_schema()
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self._init_client()
        
        # åŠ è½½åŠ¨æ€æƒé‡é…ç½®
        self.dynamic_weights = self._load_latest_weights()
        
        # åˆå§‹åŒ– LLM ç¼“å­˜
        self.cache = LLMCache()
        
        logger.info(f"AIå®¡è®¡å¼•æ“åˆå§‹åŒ–å®Œæˆ: provider={self.provider}, model={self.model}")
        logger.info(f"åŠ¨æ€æƒé‡é…ç½®: {self.dynamic_weights}")
    
    def _init_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        if self.provider == 'openai':
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=self.api_key)
                logger.info("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except ImportError:
                logger.error("OpenAI SDKæœªå®‰è£…,è¯·è¿è¡Œ: pip install openai")
                self.client = None
                
        elif self.provider == 'anthropic':
            try:
                from anthropic import Anthropic
                self.client = Anthropic(api_key=self.api_key)
                logger.info("Anthropicå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except ImportError:
                logger.error("Anthropic SDKæœªå®‰è£…,è¯·è¿è¡Œ: pip install anthropic")
                self.client = None
                
        elif self.provider == 'gemini':
            # ä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼è°ƒç”¨ Gemini API (æœ€ç¨³å®šçš„æ–¹å¼)
            # æ–‡æ¡£: https://ai.google.dev/gemini-api/docs/openai
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
                )
                logger.info(f"Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (OpenAIå…¼å®¹æ¨¡å¼): {self.model}")
            except ImportError:
                logger.error("OpenAI SDKæœªå®‰è£…,è¯·è¿è¡Œ: pip install openai")
                self.client = None
            except Exception as e:
                logger.error(f"Geminiåˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            logger.warning(f"æœªçŸ¥çš„LLMæä¾›å•†: {self.provider}")
            self.client = None
    
    def _load_prompt_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template_path = "NewsTrace_Skills/prompt_templates/semantic_audit_v2.txt"
        
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                template = f.read()
            logger.info(f"æç¤ºè¯æ¨¡æ¿åŠ è½½æˆåŠŸ: {template_path}")
            return template
        except FileNotFoundError:
            logger.warning(f"æç¤ºè¯æ¨¡æ¿æœªæ‰¾åˆ°: {template_path}, å°è¯•åŠ è½½ v1 ç‰ˆæœ¬")
            template_path_v1 = "NewsTrace_Skills/prompt_templates/semantic_audit.txt"
            try:
                with open(template_path_v1, 'r', encoding='utf-8') as f:
                    template = f.read()
                return template
            except FileNotFoundError:
                return self._get_default_prompt_template()
    
    def _get_default_prompt_template(self) -> str:
        """è·å–é»˜è®¤æç¤ºè¯æ¨¡æ¿"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–°é—»è¯­ä¹‰å®¡è®¡ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ–°é—»,è¯†åˆ«æƒ…ç»ªåŒ–ä¿®é¥°ã€é€»è¾‘æ¼æ´å’Œç¿»è¯‘å¤±çœŸã€‚

æ–°é—»æ ‡é¢˜: {title}
æ–°é—»å†…å®¹: {content}
æ–°é—»æ¥æº: {source}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºå®¡è®¡ç»“æœ:
{{
  "audit_result": {{
    "score": <0-100çš„æ•´æ•°>,
    "risk_level": "<High|Medium|Low>",
    "warnings": ["è­¦å‘Š1", "è­¦å‘Š2"]
  }},
  "recommended_tickers": [
    {{
      "code": "è‚¡ç¥¨ä»£ç ",
      "name": "è‚¡ç¥¨åç§°",
      "logic": "æ¨èé€»è¾‘"
    }}
  ]
}}
"""
    
    def _load_json_schema(self) -> Dict:
        """åŠ è½½JSON Schema"""
        schema_path = "NewsTrace_Skills/schemas/audit_result.json"
        
        try:
            with open(schema_path, 'r', encoding='utf-8') as f:
                schema = json.load(f)
            logger.info("JSON SchemaåŠ è½½æˆåŠŸ")
            return schema
        except FileNotFoundError:
            logger.warning(f"JSON Schemaæœªæ‰¾åˆ°: {schema_path}")
            return {}
    
    def _load_latest_weights(self) -> Dict:
        """ä»æ•°æ®åº“åŠ è½½æœ€æ–°æƒé‡é…ç½®"""
        # é»˜è®¤æƒé‡é…ç½®
        default_weights = {
            "hype_language": -20.0,
            "policy_demand": 15.0,
            "uncertainty": -30.0,
            "logical_rigor": 25.0,
            "data_support": 20.0
        }
        
        if self.db is None:
            logger.info("æ•°æ®åº“æœªæä¾›,ä½¿ç”¨é»˜è®¤æƒé‡é…ç½®")
            return default_weights
        
        try:
            with self.db.get_connection() as conn:
                cursor = conn.cursor()
                
                # ä»è§†å›¾è·å–æœ€æ–°æƒé‡
                cursor.execute("""
                    SELECT feature_name, current_weight
                    FROM v_latest_weights
                """)
                
                rows = cursor.fetchall()
                
                if rows:
                    weights = {}
                    for row in rows:
                        feature_name, current_weight = row
                        weights[feature_name] = float(current_weight)
                    
                    logger.info(f"ä»æ•°æ®åº“åŠ è½½äº† {len(weights)} ä¸ªæƒé‡é…ç½®")
                    return weights
                else:
                    logger.info("æ•°æ®åº“ä¸­æ— æƒé‡è®°å½•,ä½¿ç”¨é»˜è®¤é…ç½®")
                    return default_weights
                    
        except Exception as e:
            logger.error(f"åŠ è½½æƒé‡é…ç½®å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            return default_weights
    
    def audit(self, news: Dict) -> Dict:
        """
        å®¡è®¡æ–°é—»
        
        Args:
            news: æ–°é—»å­—å…¸ {title, content, source}
            
        Returns:
            å®¡è®¡ç»“æœå­—å…¸
        """
        logger.debug(f"å®¡è®¡æ–°é—»: {news.get('title', '')[:50]}")
        
        if self.client is None:
            logger.error("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return self._get_fallback_result()
        
        title = news.get('title', '')
        content = news.get('content', '')
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache.get(title, content)
        if cached_result:
            logger.info(f"ç¼“å­˜å‘½ä¸­: {title[:30]}...")
            return cached_result
        
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(news)
            
            # è°ƒç”¨LLM
            result = self._call_llm(prompt)
            
            # éªŒè¯JSON Schema
            validated_result = self._validate_result(result)
            
            # å†™å…¥ç¼“å­˜
            self.cache.set(title, content, validated_result)
            
            return validated_result
            
        except Exception as e:
            logger.error(f"å®¡è®¡å¤±è´¥: {e}")
            return self._get_fallback_result()
    
    def _build_prompt(self, news: Dict) -> str:
        """æ„å»ºæç¤ºè¯(åŒ…å«åŠ¨æ€æŒ‡ä»¤å’Œæ—¶é—´ä¸Šä¸‹æ–‡)"""
        # å…ˆç”ŸæˆåŠ¨æ€æŒ‡ä»¤
        dynamic_instruction = self._generate_dynamic_instruction()
        
        # æ–¹æ¡ˆ4: æ³¨å…¥æ—¶é—´ä¸Šä¸‹æ–‡
        current_date = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        market_context = self._get_market_context()
        
        # ä¸€æ¬¡æ€§å¡«å……æ‰€æœ‰å ä½ç¬¦
        full_prompt = self.prompt_template.format(
            title=news.get('title', ''),
            content=news.get('content', '')[:1000],  # é™åˆ¶é•¿åº¦
            source=news.get('source', 'Unknown'),
            dynamic_instruction=dynamic_instruction,
            current_date=current_date,
            market_context=market_context
        )
        
        return full_prompt
    
    def _get_market_context(self) -> str:
        """
        è·å–å½“å‰å¸‚åœºä¸Šä¸‹æ–‡æè¿°
        æ–¹æ¡ˆ4: å¢åŠ è¾“å‡ºå¤šæ ·æ€§ï¼Œå¯åç»­å¯¹æ¥å®æ—¶è¡Œæƒ…API
        """
        # éšæœºé€‰æ‹©å¸‚åœºæè¿°æ¨¡æ¿ï¼Œå¢åŠ è¾“å‡ºå¤šæ ·æ€§
        templates = [
            "å¸‚åœºæ•´ä½“æƒ…ç»ªåè°¨æ…ï¼Œå…³æ³¨æ”¿ç­–é¢å˜åŒ–",
            "Aè‚¡éœ‡è¡è°ƒæ•´ä¸­ï¼Œèµ„é‡‘åå¥½é˜²å¾¡å‹æ¿å—",
            "å¸‚åœºæ´»è·ƒåº¦æå‡ï¼Œé¢˜æè½®åŠ¨åŠ å¿«",
            "è§‚æœ›æƒ…ç»ªæµ“åšï¼Œç­‰å¾…è´¢æŠ¥å­£å‚¬åŒ–",
            "å¤–å›´å¸‚åœºæ³¢åŠ¨åŠ å‰§ï¼Œé¿é™©æƒ…ç»ªä¸Šå‡",
            "æˆäº¤é‡èç¼©ï¼Œå¸‚åœºç­‰å¾…æ–¹å‘é€‰æ‹©",
            "çƒ­ç‚¹æ¿å—è½®åŠ¨å¿«é€Ÿï¼ŒçŸ­çº¿æœºä¼šä¸ºä¸»",
            "èµ„é‡‘é¢ç›¸å¯¹å®½æ¾ï¼Œå…³æ³¨æ”¿ç­–è¾¹é™…å˜åŒ–"
        ]
        return random.choice(templates)
    
    def _generate_dynamic_instruction(self) -> str:
        """æ ¹æ®å½“å‰æƒé‡ç”ŸæˆåŠ¨æ€å®¡è®¡æŒ‡ä»¤"""
        instructions = ["### åŠ¨æ€å®¡è®¡æŒ‡ä»¤ (åŸºäºå¸‚åœºåé¦ˆ):"]
        w = self.dynamic_weights
        
        # æ–¹æ¡ˆ5: éšæœºé€‰æ‹©æœ¬æ¬¡å®¡è®¡çš„ç‰¹åˆ«å…³æ³¨ç‚¹
        special_focus_options = [
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šæ–°é—»æ¥æºçš„æƒå¨æ€§å’Œå†å²å‡†ç¡®ç‡",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šæ—¶é—´æ•æ„Ÿæ€§â€”â€”è¿™æ¡æ–°é—»çš„æ—¶æ•ˆçª—å£æœ‰å¤šé•¿ï¼Ÿ",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šé€†å‘æ€ç»´â€”â€”å¦‚æœè¿™æ¡æ–°é—»æ˜¯åˆ©ç©ºè€Œéåˆ©å¥½å‘¢ï¼Ÿ",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šæ¿å—è”åŠ¨â€”â€”å“ªäº›ç›¸å…³æ¿å—å¯èƒ½å—åˆ°æ³¢åŠï¼Ÿ",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šæƒ…ç»ªæŒ‡æ ‡â€”â€”å¸‚åœºå¯¹æ­¤ç±»æ¶ˆæ¯çš„å†å²ååº”æ¨¡å¼",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šä¿¡æ¯å¯¹ç§°æ€§â€”â€”è¯¥æ¶ˆæ¯æ˜¯å¦å·²è¢«å¸‚åœºå……åˆ†æ¶ˆåŒ–ï¼Ÿ",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šæ”¿ç­–æ•æ„Ÿåº¦â€”â€”ç›‘ç®¡å±‚å¯èƒ½å¦‚ä½•è§£è¯»æ­¤æ¶ˆæ¯ï¼Ÿ",
            "âš¡ æœ¬æ¬¡å®¡è®¡ç‰¹åˆ«å…³æ³¨ï¼šèµ„é‡‘é¢â€”â€”è¯¥æ¶ˆæ¯å¯¹å¸‚åœºæµåŠ¨æ€§æœ‰ä½•å½±å“ï¼Ÿ"
        ]
        instructions.append(random.choice(special_focus_options))
        
        # æ ‡é¢˜å…š/å¤¸å¤§è¡¨è¾¾
        if w.get("hype_language", -20) > -5:
            instructions.append("- âš ï¸ å¸‚åœºå¤„äºæƒ…ç»ªäº¢å¥‹æœŸ:æš‚åœå¯¹'å¤¸å¤§è¡¨è¾¾'çš„é™æƒ,å°†å…¶è§†ä¸ºåŠ¨é‡å› å­ã€‚")
        elif w.get("hype_language", -20) < -30:
            instructions.append("- ğŸš« é«˜åº¦è­¦æƒ•å¤¸å¤§è¡¨è¾¾:å¸‚åœºå¯¹æ ‡é¢˜å…šæƒ©ç½šä¸¥å‰,å¤§å¹…é™æƒã€‚")
        
        # æ”¿ç­–å¼ºåº¦
        if w.get("policy_demand", 15) > 20:
            instructions.append("- âœ… å¼ºè¯­æ€åå¥½:å¯¹äº'è¦æ±‚/å¿…é¡»'ç±»è¯æ±‡,ç»™äºˆé¢å¤–åŠ æƒã€‚")
        elif w.get("policy_demand", 15) < 5:
            instructions.append("- âš ï¸ æ”¿ç­–ç–²åŠ³:å¸‚åœºå¯¹æ”¿ç­–ç±»æ–°é—»ååº”é’åŒ–,é™ä½æƒé‡ã€‚")
        
        # ä¸ç¡®å®šæ€§
        if w.get("uncertainty", -30) > -15:
            instructions.append("- ğŸ“Š å®¹å¿ä¸ç¡®å®šæ€§:å¸‚åœºæ¥å—'å¯èƒ½/æˆ–å°†'ç­‰æ¨¡ç³Šè¡¨è¾¾,é€‚åº¦æ”¾å®½ã€‚")
        elif w.get("uncertainty", -30) < -40:
            instructions.append("- â›” é›¶å®¹å¿ä¸ç¡®å®šæ€§:ä¸¥æ ¼æƒ©ç½šæ¨¡ç³Šè¡¨è¾¾,è¦æ±‚æ˜ç¡®æ€§ã€‚")
        
        # é€»è¾‘ä¸¥è°¨æ€§
        if w.get("logical_rigor", 25) > 30:
            instructions.append("- ğŸ¯ é€»è¾‘ä¸ºç‹:å¸‚åœºé«˜åº¦å¥–åŠ±é€»è¾‘ä¸¥å¯†çš„åˆ†æ,å¤§å¹…åŠ åˆ†ã€‚")
        
        # æ•°æ®æ”¯æ’‘
        if w.get("data_support", 20) > 25:
            instructions.append("- ğŸ“ˆ æ•°æ®é©±åŠ¨:æœ‰å…·ä½“æ•°æ®æ”¯æ’‘çš„æ–°é—»è·å¾—æ˜¾è‘—åŠ æƒã€‚")
        
        instructions.append("\n**é‡è¦**: è¯·åœ¨è¾“å‡ºä¸­åŒ…å« `detected_features` å­—æ®µ,åˆ—å‡ºæ£€æµ‹åˆ°çš„ç‰¹å¾(å¦‚ hype_language, policy_demand ç­‰)ã€‚")
        
        return "\n".join(instructions)
    
    def _call_llm(self, prompt: str, max_retries: int = 3) -> Dict:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            è§£æåçš„JSONç»“æœ
        """
        for attempt in range(max_retries):
            try:
                if self.provider == 'openai':
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–°é—»å®¡è®¡ä¸“å®¶ã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=self.temperature,
                        max_tokens=self.max_tokens,
                        response_format={"type": "json_object"}
                    )
                    
                    content = response.choices[0].message.content
                    result = json.loads(content)
                    return result
                    
                elif self.provider == 'anthropic':
                    response = self.client.messages.create(
                        model=self.model,
                        max_tokens=self.max_tokens,
                        temperature=self.temperature,
                        messages=[
                            {"role": "user", "content": prompt}
                        ]
                    )
                    
                    content = response.content[0].text
                    result = json.loads(content)
                    return result
                    
                elif self.provider == 'gemini':
                    # ä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼
                    logger.info(f"[Gemini] è°ƒç”¨æ¨¡å‹: {self.model}")
                    
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ–°é—»å®¡è®¡ä¸“å®¶ã€‚è¯·ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=self.temperature,
                        max_tokens=self.max_tokens,
                        response_format={"type": "json_object"}
                    )
                    
                    content = response.choices[0].message.content
                    logger.info(f"[Gemini API] å“åº”æˆåŠŸ, é•¿åº¦: {len(content) if content else 0}")
                    
                    result = json.loads(content)
                    return result
                    
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    raise
                    
            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("LLMè°ƒç”¨å¤±è´¥,å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _parse_gemini_response(self, response_text: str) -> Dict:
        """
        è§£æ Gemini å“åº” (å‚è€ƒ daily_stock_analysis é¡¹ç›®å®ç°)
        
        å°è¯•ä»å“åº”ä¸­æå– JSONï¼ŒåŒ…å«å¤šç§å®¹é”™å¤„ç†
        """
        import re
        
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®°
            cleaned_text = response_text.strip()
            
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            cleaned_text = cleaned_text.strip()
            
            # å°è¯•æ‰¾åˆ° JSON å†…å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                json_str = self._fix_json_string(json_str)
                
                logger.info(f"[JSONè§£æ] æå–å†…å®¹é•¿åº¦: {len(json_str)}")
                data = json.loads(json_str)
                return data
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSON
                logger.warning(f"[JSONè§£æ] æœªæ‰¾åˆ° JSON ç»“æ„, è¿”å›é»˜è®¤ç»“æœ")
                logger.debug(f"åŸå§‹å“åº”: {response_text[:200]}")
                return self._get_fallback_result()
                
        except json.JSONDecodeError as e:
            logger.error(f"[JSONè§£æ] è§£æå¤±è´¥: {e}")
            logger.debug(f"å°è¯•è§£æçš„å†…å®¹: {response_text[:500]}")
            raise
    
    def _fix_json_string(self, json_str: str) -> str:
        """
        ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜ (å‚è€ƒ daily_stock_analysis é¡¹ç›®)
        """
        import re
        
        # ç§»é™¤ JavaScript é£æ ¼çš„æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å· (JSON ä¸å…è®¸)
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™ (Python True/False è½¬ JSON true/false)
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        # ç§»é™¤å¯èƒ½çš„ BOM æˆ–å…¶ä»–æ§åˆ¶å­—ç¬¦
        json_str = json_str.strip('\ufeff\u200b\u200c\u200d')
        
        return json_str
    
    def _validate_result(self, result: Dict) -> Dict:
        """
        éªŒè¯ç»“æœæ˜¯å¦ç¬¦åˆJSON Schema
        
        Args:
            result: LLMè¿”å›çš„ç»“æœ
            
        Returns:
            éªŒè¯åçš„ç»“æœ
        """
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if 'audit_result' not in result:
            logger.warning("ç¼ºå°‘audit_resultå­—æ®µ")
            result['audit_result'] = {
                'score': 50,
                'risk_level': 'Medium',
                'warnings': ['å®¡è®¡ç»“æœæ ¼å¼ä¸å®Œæ•´'],
                'detected_features': []  # æ–°å¢
            }
        
        if 'recommended_tickers' not in result:
            logger.warning("ç¼ºå°‘recommended_tickerså­—æ®µ")
            result['recommended_tickers'] = []
        
        # ç¡®ä¿ detected_features å­—æ®µå­˜åœ¨
        if 'detected_features' not in result['audit_result']:
            result['audit_result']['detected_features'] = []
        
        # éªŒè¯è¯„åˆ†èŒƒå›´
        score = result['audit_result'].get('score', 50)
        if not (0 <= score <= 100):
            logger.warning(f"è¯„åˆ†è¶…å‡ºèŒƒå›´: {score}, å·²ä¿®æ­£ä¸º50")
            result['audit_result']['score'] = 50
        
        # éªŒè¯é£é™©ç­‰çº§
        risk_level = result['audit_result'].get('risk_level', 'Medium')
        if risk_level not in ['High', 'Medium', 'Low']:
            logger.warning(f"æ— æ•ˆçš„é£é™©ç­‰çº§: {risk_level}, å·²ä¿®æ­£ä¸ºMedium")
            result['audit_result']['risk_level'] = 'Medium'
        
        # é™åˆ¶æ¨èæ ‡çš„æ•°é‡
        if len(result['recommended_tickers']) > 3:
            logger.warning(f"æ¨èæ ‡çš„è¿‡å¤š: {len(result['recommended_tickers'])}, å·²æˆªå–å‰3ä¸ª")
            result['recommended_tickers'] = result['recommended_tickers'][:3]
        
        return result
    
    def _get_fallback_result(self) -> Dict:
        """è·å–é™çº§ç»“æœ"""
        return {
            'audit_result': {
                'score': 50,
                'risk_level': 'Medium',
                'warnings': ['å®¡è®¡å¼•æ“ä¸å¯ç”¨,ä½¿ç”¨é™çº§ç»“æœ']
            },
            'recommended_tickers': []
        }
